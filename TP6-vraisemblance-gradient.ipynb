{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nom, prenom et groupe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP6 : Maximum de vraisemblance via l'algorithme de montée de gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1606831889555,
     "user": {
      "displayName": "Stephan Semirat",
      "photoUrl": "",
      "userId": "06413469689434144964"
     },
     "user_tz": -60
    },
    "id": "Zupdaax6Xf8b"
   },
   "outputs": [],
   "source": [
    "# Chargement des bibliothèques\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "print('Bibliothèques chargées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problème A (à traiter avec l'enseignant) ##\n",
    "\n",
    "On considère les données $X_j=(X_{j1},X_{j2})\\mapsto Y_j$, pour $j\\in\\{1,2,3,4\\}$, avec :\n",
    "\n",
    "$X_1=(2,0)$, $X_2=(3,2)$, $X_3=(0,3)$. $X_3=(3,4)$, et\n",
    "\n",
    "$Y_1=0$, $Y_2=0$, $Y_3=1$, $Y_4=1$.\n",
    "\n",
    "Ces données sont représentées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Définition des données\n",
    "\n",
    "X1=[2,3,0,3]\n",
    "X2=[0,2,3,4]\n",
    "Y=[0,0,1,1]\n",
    "\n",
    "#Représentation graphique des données\n",
    "\n",
    "plt.axis([-1,5,-1,5]) #xmin,xmax,ymin,ymax\n",
    "for i in range(len(X1)):\n",
    "    if Y[i]==0:\n",
    "        color='blue'\n",
    "    else:\n",
    "        color='red'\n",
    "    plt.plot([X1[i]],[X2[i]],'o',c=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite, on va chercher des coefficients $b$ et $W=\\begin{pmatrix}w_1\\\\w_2\\end{pmatrix}$ maximisant la vraisemblance de la loi de probabilité définie par $$\\Pr(Y=1|X)=\\sigma(b+w_1x_1+w_2x_2).$$\n",
    "où $\\sigma$ est la fonction sigmoïde, définie pour tout $x$ dans $R$ par $$\\sigma(x)=\\frac{1}{1+e^{-x}}.$$\n",
    "\n",
    "La vraisemblance de cette loi est donnée par \n",
    "$$L(b,W)=\\prod\\limits_{j:Y_j=1}\\sigma(b+w_1x_{j1}+w_2x_{j2})\\times\\prod\\limits_{j:Y_j=0}(1-\\sigma(b+w_1x_{j1}+w_2x_{j2}))$$\n",
    "\n",
    "On rappelle (vu en cours) que $\\sigma(x)\\simeq 1$ dès que $x>>0$ ($x$ très supérieur à $0$), et $\\sigma(x)\\simeq 0$ dès que $x<<0$ ($x$ très inférieur à $0$).\n",
    "\n",
    "La vraisemblance est donc grande si les coefficients $b$, $w_1$ et $w_2$ vérifient pour tout $j\\in\\{1,2,3,4\\}$ :\n",
    "\n",
    "$$(C_j):\\left\\{\\begin{array}{l}b+w_1x_{j1}+w_2x_{j2}>>0\\text{ si }Y_j=1\\\\b+w_1x_{j1}+w_2x_{j2}<<0\\text{ si }Y_j=0\\end{array}\\right.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résolution \"à la main\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "1. Ecrire les 4 conditions $(C_j)$ que doivent satisfaire $b$, $w_1$ et $w_2$ :\n",
    "  - Condition (C1) issue de la donnée X1,Y1 : ...\n",
    "  - Condition (C2) issue de la donnée X2,Y2 : ...\n",
    "  - Condition (C3) issue de la donnée X3,Y3 : ...\n",
    "  - Condition (C4) issue de la donnée X4,Y4 : ...\n",
    "\n",
    "2. Proposer une valeur pour $b$, $w_1$, $w_2$ satisfaisant les 4 conditions précédentes.\n",
    "\n",
    "*Indication* : tracer sur papier une droite séparant les données et un point $Z=(x_1(Z),x_2(Z))$ situé sur cette droite, puis déterminer les coefficients $b$, $w_1$ et $w_2$ d'une équation la forme $b+w_1x_1+w_2x_2=0$ de cette droite à partir des propriétés :\n",
    "- le gradient $(w_1,w_2)$ de cette droite est orienté vers les $Y=1$\n",
    "- les coordonnées de $Z$ satisfont l'équation de la droite : $b+w_1x_1(Z)+w_2x_2(Z)=0$\n",
    "\n",
    "Réponse : b=.... , w1=.... , w2=....\n",
    "\n",
    "3. Vérifier que la solution trouvée à la question précédente vérifie les 4 conditions de la question 1 :\n",
    "\n",
    "  - Condition (C1) issue de la donnée X1,Y1 : ... : vérifiée\n",
    "  - Condition (C2) issue de la donnée X2,Y2 : ... : vérifiée\n",
    "  - Condition (C3) issue de la donnée X3,Y3 : ... : vérifiée\n",
    "  - Condition (C4) issue de la donnée X4,Y4 : ... : vérifiée\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation de la solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction sigma\n",
    "def sigma(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "print('Fonction sigma enregistrée')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Compléter la cellule ci-dessous afin de compléter le graphique généré avec les courbes de niveaux de la fonctionn $(x_1,x_2)\\mapsto\\sigma(b+w_1x_1+w_2x_2)$ trouvée dans l'exercice précédent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Courbes de niveau de la fonction sigma(b+w1x1+w2x2)\n",
    "\n",
    "# Calcul du tableau de valeurs (compléter avec les bonnes valeurs de b, w1, w2)\n",
    "x1list=np.linspace(-1,5,50)\n",
    "x2list=np.linspace(-1,5,50)\n",
    "sigmalist=[[sigma(...+...*x1+...*x2) for x1 in x1list] for x2 in x2list]\n",
    "\n",
    "# Dessin des courbes de niveau\n",
    "plt.axis([-1,5,-1,5])\n",
    "plt.contour(x1list,x2list,sigmalist,100) # dessine 100 courbes de niveau de sigma(b+w1x1+w2x2)\n",
    "plt.colorbar()\n",
    "\n",
    "# Nuage de points\n",
    "for i in range(len(X1)):\n",
    "    if Y[i]==0:\n",
    "        color='blue'\n",
    "    else:\n",
    "        color='red'\n",
    "    plt.plot([X1[i]],[X2[i]],'o',c=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détermination algorithmique d'une solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite, on va déterminer une fonction $b+W\\cdot X$ séparant au mieux les données à l'aide d'un algorithme de *montée* de gradient sur la fonction de *log-vraisemblance*, qu'il s'agit de *maximiser*.\n",
    "\n",
    "On rappelle que la log vraisemblance est donnée par :\n",
    "$$\\ln(L(b,W))=\\sum\\limits_{j:Y_j=1}\\ln(\\sigma(b+w_1x_{j1}+w_2x_{j2}))+\\sum\\limits_{j:Y_j=0}\\ln((1-\\sigma(b+w_1x_{j1}+w_2x_{j2})))$$\n",
    "\n",
    "L'algorithme de montée de gradient est tel que, à chaque itération on calcule :\n",
    "- $b[i+1]=b[i]+\\tau\\times\\frac{\\partial \\ln(L(b,W))}{\\partial b}$\n",
    "- $w_1[i+1]=w_1[i]+\\tau\\times\\frac{\\partial \\ln(L(b,W))}{\\partial w_1}$\n",
    "- $w_2[i+1]=w_2[i]+\\tau\\times\\frac{\\partial \\ln(L(b,W))}{\\partial w_2}$\n",
    "\n",
    "Pour le programmer, on a donc besoin des dérivées de la log vraisemblance, données par (cf cours) :\n",
    "- $\\frac{\\partial \\ln(L(b,W))}{\\partial b}=\\sum\\limits_j\\left(Y_j-\\sigma(b+w_1x_{j1}+w_2x_{j_2}\\right)$\n",
    "- $\\frac{\\partial \\ln(L(b,W))}{\\partial w_1}=\\sum\\limits_j\\left(Y_j-\\sigma(b+w_1x_{j1}+w_2x_{j_2}\\right)x_{j1}$\n",
    "- $\\frac{\\partial \\ln(L(b,W)}{\\partial w_2}=\\sum\\limits_j\\left(Y_j-\\sigma(b+w_1x_{j1}+w_2x_{j_2}\\right)x_{j2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux cellules ci-dessous définisse les fonctions :\n",
    "- `gradlnL(b,w1,w2)`, qui renvoit le gradient de la log-vraisemblance calculée en (b,w1,w2)\n",
    "- `montee(b,w1,w2,tau,tolerance,nbiterationsmax)`, qui effectue l'algorithme de montee de gradient et renvoit la liste `[b[i],w1[i],w2[i]]` des coefficients atteints par l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction renvoyant le gradient de la log vraisemblance associée à b,w1,w2\n",
    "def gradlnL(b,w1,w2):\n",
    "    return [np.sum([Y[j]-sigma(b+w1*X1[j]+w2*X1[j]) for j in range(len(X1))]),\n",
    "            np.sum([(Y[j]-sigma(b+w1*X1[j]+w2*X2[j]))*X1[j] for j in range(len(X1))]),\n",
    "            np.sum([(Y[j]-sigma(b+w1*X1[j]+w2*X2[j]))*X2[j] for j in range(len(X1))])\n",
    "           ] \n",
    "print('Fonction gradlnL enregistrée')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithme de montee de gradient initialisé\n",
    "def montee(b,w1,w2,tau,tolerance,NbIterationsMax):\n",
    "    diverge=False\n",
    "    L=[]\n",
    "    for i in range(NbIterationsMax):\n",
    "        try: # traitement des erreurs si l'algorithme diverge\n",
    "            if (b==float('inf')) or (w1==float(\"inf\")) or (w2==float(\"inf\")):\n",
    "                raise(OverflowError)\n",
    "            g = gradlnL(b,w1,w2)\n",
    "            if g[0]**2+g[1]**2+g[2]**2<tolerance:\n",
    "                print('L\\'algorithme a convergé en',i,'itérations. \\nSolution atteinte :\\n b=',b,'\\n w1=',w1,'\\n w2=',w2,'\\nGradient :',g,'\\nNorme du gradient:',g[0]**2+g[1]**2+g[2]**2)\n",
    "                L.append([b,w1,w2])\n",
    "                return L\n",
    "            L.append([b,w1,w2])\n",
    "            b=b+tau*g[0]\n",
    "            w1=w1+tau*g[1]\n",
    "            w2=w2+tau*g[2]\n",
    "        except OverflowError as err: # traitement de l'erreur \"overflow\"\n",
    "            print('L\\'algorithme a divergé.\\n Solution atteinte :\\n b=',b,'\\n w1=',w1,'\\n w2=',w2,'\\nGradient :',g,'\\nNorme du gradient:',g[0]**2+g[1]**2+g[2]**2)\n",
    "            diverge=True\n",
    "            break\n",
    "    if (diverge==False):        \n",
    "        print('L\\'algorithme n\\'a pas convergé.\\n Solution atteinte :\\n b=',b,'\\n w1=',w1,'\\n w2=',w2,'\\nGradient :',g,'\\nNorme du gradient:',g[0]**2+g[1]**2+g[2]**2)\n",
    "    return L\n",
    "\n",
    "print('Fonction montee enregistrée')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "La cellule ci-dessous permet d'effectuer l'algorithme, puis de représenter les droites d'équation `b[i]+w1[i]*x1+w2[i]*x2=0` atteintes par l'algorithme. L'algorithme converge si le gradient de la log-vraisemblance atteint est suffisamment petit (inférieur à `tolerance`).\n",
    "\n",
    "1. Effectuer l'algorithme initialisé à la droite d'équation $x_2=1$ (déterminer les $b$, $w_1$ et $w_2$ associés), avec un pas $\\tau=0.1$, une tolérance de $0.1$ et un nombre d'itérations maximum de 50 (vous devriez obtenir une convergence en 27 itérations).\n",
    "2. En utilisant la sortie texte de l'lagorithme, donner l'équation de la droite atteinte par l'algorithme. Cette droite sépare-t-elle linéairement les données ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculs de la suite des [b[i],w1[i],w2[i]] via l'algorithme\n",
    "ListeBW=montee(...,...,...,0.01,0.1,50)\n",
    "\n",
    "# Représentation graphique des droites b[i]+w1[i]*x1+w2[i]*x2\n",
    "for i in range(len(ListeBW)):\n",
    "    W=ListeBW[i]\n",
    "    b=W[0]\n",
    "    w1=W[1]\n",
    "    w2=W[2]\n",
    "    if (w2!=0):\n",
    "        plt.plot([-1,5],[(-w1*(-1)-b)/w2,(-w1*5-b)/w2],c=\"black\",alpha=0.1+0.9*i/(len(ListeBW)-1))\n",
    "    elif (w1!=0):\n",
    "        plt.plot([(-w2*(-1)-b)/w1,(-w2*5-b)/w1],[-1,5],c=\"black\",alpha=0.1+0.9*i/(len(ListeBW)-1))        \n",
    "    # alpha est un paramètre de transparence variant ici de 0.1 à 0.9 avec la valeur de i\n",
    "\n",
    "# Nuage de points\n",
    "for i in range(len(X1)):\n",
    "    if Y[i]==0:\n",
    "        color='blue'\n",
    "    else:\n",
    "        color='red'\n",
    "    plt.plot([X1[i]],[X2[i]],'o',c=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problème B (à traiter en autonomie) #\n",
    "\n",
    "À vous de généraliser les calculs précédents avec un nuage de 40 données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création aléatoire des données\n",
    "\n",
    "# Cette cellule n'est à exécuter qu'une fois, afin de générer des données aléatoires,\n",
    "# et afin de les recopier dans la cellule suivante\n",
    "\n",
    "# on génère 40 données (X1j,X2j,Yj), avec Yj=0 ou 1\n",
    "# données centrées autour de 2 centres\n",
    "X, Y = make_blobs(n_samples=40, centers=[[-0.5,-0.5],[0.5,0.5]], n_features=2, cluster_std=0.5,center_box=(-1,1))\n",
    "print('Liste X1 des Xj1 (à copier coller dans la cellule ci-dessous): \\n\\n',np.array2string(X[:,0],separator=',',max_line_width=10000).replace('\\n', ''),'\\n')\n",
    "print('Liste X2 des Xj2 (à copier coller dans la cellule ci-dessous): \\n\\n',np.array2string(X[:,1],separator=',',max_line_width=10000).replace('\\n', ''),'\\n')\n",
    "print('\\nListe Y des Yj (à copier coller dans la cellule ci-dessous): \\n\\n',np.array2string(Y,separator=',',max_line_width=10000).replace('\\n', ''),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifier en copiant collant avec les données générées aléatoirement ci-dessus\n",
    "# attention à bien identifier les crochets fermant et ouvrant\n",
    "\n",
    "X1=[...]\n",
    "X2=[...]\n",
    "Y=[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualisation du nuage de points\n",
    "# (Attention à la fenêtre, qui est différente de celle du problème A)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "1. Utiliser la cellule ci-dessous pour déterminer une droite séparant au mieux les données à l'aide de l'algorithme de montée de gradient (algorithme convergent avec avec une tolerance à 0.1, 50 itérations max)\n",
    "2. Utiliser la cellule suivante pour représenter les étapes de l'algorithme ainsi que le nuage de points.\n",
    "3. Compléter la cellule suivante avec les paramètres utilisés et avec les résultats obtenus (pour une loi $(x1,x2)\\mapsto \\sigma(b+w_1x_1+w_2x_2)$ obtenue, un *faux positif* est tel que $\\sigma(b+w_1x_{j1}+w_2x_{j2})>0.5$ alors que $Y_j=0$, et un *faux négatif* est tel que $\\sigma(b+w_1x_{j1}+w_2x_{j2})<0.5$ alors que $Y_j=1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution algorithmique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation graphique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponses à compléter **\n",
    "\n",
    "- Valeurs initiales : ...\n",
    "\n",
    "- tolerance : ..., facteur $\\tau$ : ...\n",
    "- Convergence en ... itérations\n",
    "\n",
    "- Droite obtenu : ...\n",
    "\n",
    "- Nombre de faux positifs :\n",
    "\n",
    "- Nombre de faux négatifs :"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL5iJTlZCmM9764vTsZljv",
   "collapsed_sections": [],
   "name": "descente-deux-variables.ipynb",
   "provenance": [
    {
     "file_id": "164i4yxW6Yks9BXBhzNAJHUMyX1UBjEp3",
     "timestamp": 1606828072802
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
