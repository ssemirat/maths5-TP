{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nom, prénom, groupe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP7 : Reconnaissance d'une diagonale dans carré 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na-Yck4lZiN1"
   },
   "source": [
    "## Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1606831889555,
     "user": {
      "displayName": "Stephan Semirat",
      "photoUrl": "",
      "userId": "06413469689434144964"
     },
     "user_tz": -60
    },
    "id": "Zupdaax6Xf8b"
   },
   "outputs": [],
   "source": [
    "# Bibliothèques utilisées\n",
    "\n",
    "from matplotlib import pyplot as plt # graphique\n",
    "import numpy as np # mathématiques\n",
    "import pandas as pd # manipulation des données\n",
    "\n",
    "print('Bibliothèques chargées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lecture des données depuis un fichier\n",
    "data=pd.read_csv(\"diag2x2.csv\",sep=\",\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problème A (à traiter avec l'enseignant)\n",
    "\n",
    "Les données $(X_j,Y_j)$, $j\\in\\{0,\\ldots,15\\}$, ci-dessus représentent les 16 carrés composés de 4 cases \n",
    "<table><tr><td >x1</td><td>x2</td></tr><tr><td>x3</td><td>x4</td></tr></table>\n",
    "chaque case pouvant prendre la valeur 0 ou 1, ainsi que la valeur $Y_j=0$ ou $Y_j=1$ selon que le carré comporte *exactement* une diagonale de 1 (les deux autres cases étant à 0).\n",
    "\n",
    "Dans la suite, on tente de déterminer une fonction définie par l'expression $$R_{W,W_1,W_2}(x_1,x_2,x_3,x_4)=\\sigma\\bigg(h_W\\bigg(\\sigma\\big(h_{W_1}(x_1,x_2,x_3,x_4)\\big),\\sigma(h_{W_2}\\big(x_1,x_2,x_3,x_4\\big)\\bigg)\\bigg)$$ avec\n",
    "$$W=(b,w_1,w_2)\\text{ et }h_W(s_1,s_2)=b+w_1s_1+w_2s_2$$\n",
    "$$W_1=(b_1,w_{11},w_{12},w_{13},w_{14})\\text{ et }h_{W_1}(x_1,x_2,x_3,x_4)=b_1+w_{11}x_1+w_{12}x_2+w_{13}x_3+w_{14}x_4,$$\n",
    "$$W_2=(b_2,w_{21},w_{22},w_{23},w_{24})\\text{ et }h_{W_2}(x_1,x_2,x_3,x_4)=b_2+w_{21}x_1+w_{22}x_2+w_{23}x_3+w_{24}x_4,$$\n",
    "permettant d'approximer au mieux $Y_j$ à travers $R(x_{j1},x_{j2},x_{j3},x_{j4})$, pour chaque donnée $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Les 16 carrés sont enregistrés en Python sous forme de ligne de 5 valeurs, numérotées de 0 à 15.\n",
    "Quels sont les numéros des données correspondant à un carré comportant exactement une diagonale de 1 ?\n",
    "\n",
    "Réponse : lignes n° ... et n° ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des données du tableau de données (\"dataframe\") chargé :\n",
    "# extraction des entrées Xj\n",
    "Xdata=data.drop(['Y'],axis=1) # la variable Xdata contient toutes les colonnes sauf la colonne Y (de l'axe 1=\"colonnes\")\n",
    "# extraction des sorties Yj\n",
    "Ydata=data['Y'] # La variable Ydata contient la colonne Y\n",
    "\n",
    "n=len(Xdata) # Nombre de lignes de données (ici 16)\n",
    "d=len(Xdata.iloc[0]) # Nombre de colonnes de X[0] (ici 4)\n",
    "print(\"Données et tailles des données définies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation par un réseau à 1 couche cachée de 2 neurones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Représenter (sur papier) par un graphe de calcul le réseau de neurones associé à la fonction $X\\mapsto R(X)$, où $X=(x_1,x_2,x_3,x_4)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Compléter la cellule ci-dessous afin de définir la fonction `R(W,W1,W2,j)`, qui doit retourner la valeur de $R(X_j)$ avec comme paramètres entrant :\n",
    "- `W`, qui représente la liste `[b,w_1,w_2]` (paramètres associés à $h_W$)\n",
    "- `W1` et `W2`, qui représentent les listes `[b1,w11,w12,w13,w14]` (paramètres associés à $h_{W_1}$) et `[b2,w21,w22,w23,w24]` (paramètres associés à $h_{W_2}$) respectivement\n",
    "- `j`, qui représente le numéro $j$ de la donnée considérée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réseau\n",
    "def sigma(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def R(W,W1,W2,j):\n",
    "    Xj=Xdata.iloc[j] # Xj=[Xj[0],Xj[1],Xj[2],Xj[3]] est la ligne j du tableau Xdata\n",
    "    hW1=...\n",
    "    hW2=...\n",
    "    hW=...\n",
    "    R=...\n",
    "    return R\n",
    "\n",
    "print('Fonction sigma et R définies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Compléter la cellule suivante afin de vérifier que la fonction $$R_{W,W_1,W_2}(X)=\\sigma(-25+28\\sigma(h_{W_1}(X))-13\\sigma(h_{W_2}(X)))$$ avec $$h_{W_1}(X)=0-3x_1+1.5x_2+1.5x_3+9x_4$$\n",
    "et $$h_{W_2}(X)=-14-4x_1+4x_2+4x_3+14x_4$$\n",
    "répond au problème posé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=...\n",
    "W2=...\n",
    "W=...\n",
    "for j in range(n):\n",
    "    print('Y observé :',Ydata.iloc[j],' Y calculé par la fonction R:',R(W,W1,W2,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La détermination des coeffcients `W=[b,w1,w2]`, `W1=[b1,w11,w12,w13,w14]` et `W2=[b2,w21,w22,w23,w24]` permettant d'approximer la relation entre $X$ et $Y$ par $Y=R_{W,W_1,W_2}(X)$ se fait, à partir des données, par minimisation de la fonction définie par $$f(W,W_1,W_2)=\\frac{1}{2}\\sum\\limits_{j=0}^{15}(R_{W,W_1,W_2}(X)-Y_j)^2.$$\n",
    "\n",
    "La minimisation se fait par descente de gradient.\n",
    "\n",
    "Puisque la dérivée d'une somme est la somme des dérivées, le gradient de $f$ est égal à la somme des gradients des fonctions $E_j$, définies pour chaque $j$ par $$E_j(W,W_1,W_2)=\\frac{1}{2}(R_{W,W_1,W_2}(X)-Y_j)^2.$$\n",
    "\n",
    "La fonction python `gradE` ci-dessous permet de calculer *par retropropagation* le gradient de $E_j$ par rapport à *chacun des paramètres* contenu dans les listes $W$, $W_1$ et $W_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient par rétropropagation\n",
    "\n",
    "def gradE(W,W1,W2,j):\n",
    "    b,w1,w2=W[0],W[1],W[2]\n",
    "    b1,w11,w12,w13,w14=W1[0],W1[1],W1[2],W1[3],W1[4]\n",
    "    b2,w21,w22,w23,w24=W2[0],W2[1],W2[2],W2[3],W2[4]\n",
    "    Xj=Xdata.iloc[j]\n",
    "    Yj=Ydata.iloc[j]\n",
    "    h1=b1+w11*Xj[0]+w12*Xj[1]+w13*Xj[2]+w14*Xj[3]\n",
    "    h2=b2+w21*Xj[0]+w22*Xj[1]+w23*Xj[2]+w24*Xj[3]    \n",
    "    H=b+w1*sigma(h1)+w2*sigma(h2)\n",
    "    sH=sigma(H)\n",
    "    sh1=sigma(h1)\n",
    "    sh2=sigma(h2)\n",
    "    dsH=sH*(1-sH)\n",
    "    dsh1=sh1*(1-sh1)\n",
    "    dsh2=sh2*(1-sh2)\n",
    "    dEdsH=sH-Yj\n",
    "    dsHdb=dsH*1\n",
    "    dsHdw1=dsH*sh1\n",
    "    dsHdw2=dsH*sh2\n",
    "    dsHdsh1=dsH*w1\n",
    "    dsHdsh2=dsH*w2\n",
    "    dsh1db1=dsh1*1\n",
    "    dsh1dw11=dsh1*Xj[0]\n",
    "    dsh1dw12=dsh1*Xj[1]\n",
    "    dsh1dw13=dsh1*Xj[2]\n",
    "    dsh1dw14=dsh1*Xj[3]\n",
    "    dsh2db2=dsh2*1\n",
    "    dsh2dw21=dsh2*Xj[0]\n",
    "    dsh2dw22=dsh2*Xj[1]\n",
    "    dsh2dw23=dsh2*Xj[2]\n",
    "    dsh2dw24=dsh2*Xj[3]\n",
    "    dEdb=dEdsH*dsHdb\n",
    "    dEdw1=dEdsH*dsHdw1\n",
    "    dEdw2=dEdsH*dsHdw2\n",
    "    dEdb1=dEdsH*dsHdsh1*dsh1db1\n",
    "    dEdw11=dEdsH*dsHdsh1*dsh1dw11\n",
    "    dEdw12=dEdsH*dsHdsh1*dsh1dw12\n",
    "    dEdw13=dEdsH*dsHdsh1*dsh1dw13\n",
    "    dEdw14=dEdsH*dsHdsh1*dsh1dw14\n",
    "    dEdb2=dEdsH*dsHdsh2*dsh2db2\n",
    "    dEdw21=dEdsH*dsHdsh2*dsh2dw21\n",
    "    dEdw22=dEdsH*dsHdsh2*dsh2dw22\n",
    "    dEdw23=dEdsH*dsHdsh2*dsh2dw23\n",
    "    dEdw24=dEdsH*dsHdsh2*dsh2dw24\n",
    "    return [[dEdb,dEdw1,dEdw2],[dEdb1,dEdw11,dEdw12,dEdw13,dEdw14],[dEdb2,dEdw21,dEdw22,dEdw23,dEdw24]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "À l'aide du graphe de calcul de la fonction $R$ (réseau de neurones), expliciter chacune des dérivées partielles qu'il est nécessaire de calculer pour obtenir la valeur de $\\frac{\\partial E_5}{\\partial w_{23}}(W,W_1,W_2)$, et vérifier ce calcul dans ce code de la fonction `gradE` ci-dessus.\n",
    "\n",
    "*Réponse:*\n",
    "\n",
    "Dérivées partielles utilisées pour calculer $\\frac{\\partial E_5}{\\partial w_{23}}(W,W_1,W_2)$ :\n",
    "- Dérivée de ... par rapport à ..., identifié par la variable ... dans le code\n",
    "- Dérivée de ... par rapport à ..., identifié par la variable ... dans le code\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Utiliser la cellule ci-dessous pour calculer $R_{W,W_1,W_2}(X_5)$ et $\\frac{\\partial E_5}{\\partial w_{23}}(W,W_1,W_2)$ en :\n",
    "$$W=(b,w_1,w_2)=(1,0,0)$$\n",
    "$$W_1=(b_1,w_{11},w_{12},w_{13},w_{14})=(1,1,1,1,1)$$\n",
    "et $$W_2=(b_1,w_{21},w_{22},w_{23},w_{24})=(1,0,0,0,0).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=...\n",
    "W1=...\n",
    "W2=...\n",
    "gradE5=...\n",
    "print('$R_{W,W_1,W_2}(X_5)=$',...)\n",
    "print('$\\frac{\\partial E_5}{\\partial w_{23}}(W,W_1,W_2)=$',...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme de descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante implémente une *version partielle* de l'algorithme de descente de gradient.\n",
    "\n",
    "Comme il y a 16 données, la fonction f est une somme de 16 carrés.\n",
    "\n",
    "L'algorithme de descente gradient, visant à minimiser $f$, doit rendre chacun des carrés petits (sans augmenter les autres).\n",
    "\n",
    "L'algorithme de descente de gradient ci-dessous effectue une descente de gradient sur seulement 5 termes de la somme, qui sont *choisis au hasard* à chaque pas de l'algorithme.\n",
    "\n",
    "Cette méthode (standard) diminue les calculs effectués à chaque pas de l'algorithme, tout en permettant en général de *probablement* réduire la valeur de $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descente(W,W1,W2,tau=0.01,tolerance=1e-2,NbIterationsMax=1000):\n",
    "    diverge=False\n",
    "    for i in range(NbIterationsMax):\n",
    "        batch=np.random.randint(0, 16, 5) # 5 entiers aléatoires choisis entre 0 et 15\n",
    "        g=[[0,0,0],[0,0,0,0,0],[0,0,0,0,0]] # gradient courant, initialisé à un gradient nul\n",
    "        for j in batch: # j parcourt 5 données aléatoires\n",
    "            gg=gradE(W,W1,W2,j) # calcul du gradient de la fonction associée à la donnée n°j\n",
    "            g = [np.add(g[0],gg[0]),np.add(g[1],gg[1]),np.add(g[2],gg[2])] # cumul du gradient gg au gradient courant            \n",
    "        try: # traitement des erreurs si l'algorithme diverge\n",
    "            if (W[0]==float('inf')) or (W[1]==float(\"inf\")) or (W[2]==float(\"inf\"))\\\n",
    "            or (W1[0]==float('inf')) or (W1[1]==float(\"inf\")) or (W1[2]==float(\"inf\")) or (W1[3]==float(\"inf\")) or (W1[4]==float(\"inf\"))\\\n",
    "            or (W2[0]==float('inf')) or (W2[1]==float(\"inf\")) or (W2[2]==float(\"inf\")) or (W2[3]==float(\"inf\")) or (W2[4]==float(\"inf\")):\n",
    "                raise(OverflowError)\n",
    "            ng=np.sqrt(np.sum([np.sum([gi**2 for gi in g[k]]) for k in range(2)]))/len(batch) # somme des carrés des coordonnées de g\n",
    "            if ng<tolerance:\n",
    "                print('L\\'algorithme a convergé en',i,'itérations. \\nSolution atteinte :\\n W=',W,'\\n W1=',W1,'\\n W2=',W2,'\\nGradient :',g)\n",
    "                return [W,W1,W2]\n",
    "            W=[W[k]-tau*g[0][k] for k in range(3)]\n",
    "            W1=[W1[k]-tau*g[1][k] for k in range(5)]\n",
    "            W2=[W2[k]-tau*g[2][k] for k in range(5)]\n",
    "        except OverflowError as err: # traitement de l'erreur \"overflow\"\n",
    "            print('L\\'algorithme a divergé \\nSolution atteinte :\\n W=',W,'\\n W1=',W1,'\\n W2=',W2,'\\nGradient :',g)\n",
    "            diverge=True\n",
    "            break\n",
    "    if (diverge==False):\n",
    "        print('L\\'algorithme n\\'a pas convergé \\nSolution atteinte :\\n W=',W,'\\n W1=',W1,'\\n W2=',W2,'\\nGradient :',g,'\\n Norme :',ng)\n",
    "    return [W,W1,W2]\n",
    "\n",
    "print('Fonction descente définie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Dans l'algorithme de descente de gradient ci-dessus, que désigne la variable `batch` et que calcule les lignes de code suivantes :\n",
    "\n",
    "`g=[[0,0,0],[0,0,0,0,0],[0,0,0,0,0]]`  \n",
    "`for j in batch:`  \n",
    "`    gg=gradE(W,W1,W2,j)`  \n",
    "`    g = [np.add(g[0],gg[0]),np.add(g[1],gg[1]),np.add(g[2],gg[2])]`\n",
    "?\n",
    "    \n",
    "*Réponse :*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "En utilisant la cellule suivante, faire converger l'algorithme avec une tolérance de $10^{-4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "descente([1,0,0],[1,1,1,1,1],[1,0,0,0,0],0.01,0.0001,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Compléter la boucle suivante afin de vérifier que les paramètres atteints par l'algorithme de descente répondent au problème posé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=...\n",
    "W1=...\n",
    "W2=...\n",
    "for j in range(n):\n",
    "    print('Y observé :',Ydata.iloc[j],' Y calculé :',R(W,W1,W2,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problème B (à faire en autonomie)\n",
    "\n",
    "Déterminer les coefficients d'un réseau de neurones qui identifie si un carré de 4 cases contient exactement une ligne de 1.\n",
    "\n",
    "À cette fin, vous pourrez au préalable modifier les données `Ydata[j]`, en modifiant les valeurs correspondant aux carrés visés :\n",
    "- Ydata[j] doit être égal à 1 si le carré contient exactement une ligne de 1\n",
    "- Ydata[j] doit être égal à 0 si le carré ne contient pas exactement une ligne de 1\n",
    "\n",
    "(par exemple `Ydata[10]=0` affecte la valeur $0$ à $Y_{10}$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification des données Ydata :\n",
    "Ydata[...]=...\n",
    "Ydata[...]=...\n",
    "Ydata[...]=...\n",
    "Ydata[...]=...\n",
    "\n",
    "# Vérification des données :\n",
    "\n",
    "for j in range(n):\n",
    "    print('X :',Xdata.iloc[j],', Y correspondant :',Ydata.iloc[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire convergeer l'algorithme (tolerance à 10^-4) pour ces nouvelles données :\n",
    "\n",
    "descente([1,0,0],[1,1,1,1,1],[1,0,0,0,0],0.01,0.0001,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des valeurs de la fonction R obtenue :\n",
    "\n",
    "W=...\n",
    "W1=...\n",
    "W2=...\n",
    "for j in range(n):\n",
    "    print('Y observé :',Ydata.iloc[j],' Y calculé :',R(W,W1,W2,j))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL5iJTlZCmM9764vTsZljv",
   "collapsed_sections": [],
   "name": "descente-deux-variables.ipynb",
   "provenance": [
    {
     "file_id": "164i4yxW6Yks9BXBhzNAJHUMyX1UBjEp3",
     "timestamp": 1606828072802
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
